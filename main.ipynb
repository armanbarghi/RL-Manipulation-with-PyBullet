{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import math\n",
    "import time\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "from src.physics_utils import PyBulletSim, CameraManager\n",
    "from src.robot_manager import RobotController\n",
    "\n",
    "class RobotGymEnv(gym.Env):\n",
    "\tmetadata = {'render_modes': ['human', 'rgb_array']}\n",
    "\n",
    "\tdef __init__(self, n_directions=8, render_mode='human', max_steps=200):\n",
    "\t\tsuper(RobotGymEnv, self).__init__()\n",
    "\t\t\n",
    "\t\tself.n_directions = n_directions\n",
    "\t\tself.render_mode = render_mode\n",
    "\t\tself.max_steps = max_steps\n",
    "\t\t\n",
    "\t\t# --- Action Space ---\n",
    "\t\tself.action_space = spaces.Discrete(n_directions + 2)\n",
    "\t\t\n",
    "\t\t# --- Observation Space ---\n",
    "\t\t# [EE_x, EE_y, EE_yaw, Cube_x, Cube_y, Target_x, Target_y]\n",
    "\t\tself.observation_space = spaces.Box(\n",
    "\t\t\tlow=-np.inf, high=np.inf, shape=(7,), dtype=np.float32\n",
    "\t\t)\n",
    "\n",
    "\t\t# Initialize Simulation\n",
    "\t\tconnection_mode = p.GUI if render_mode == 'human' else p.DIRECT\n",
    "\t\tself.sim = PyBulletSim(connection_mode)\n",
    "\t\t\n",
    "\t\t# --- Load Table & Define Boundaries ---\n",
    "\t\tp.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "\t\tself.table_id = p.loadURDF(\"table/table.urdf\", basePosition=[0.5, 0, 0], baseOrientation=[0, 0, 1, 1], useFixedBase=True)\n",
    "\n",
    "\t\t# Define boundaries (Table surface area)\n",
    "\t\tself.x_min, self.x_max = 0.2, 0.8\n",
    "\t\tself.y_min, self.y_max = -0.3, 0.3\n",
    "\t\tself.z_height = 0.65  # Height to hover above table\n",
    "\n",
    "\t\t# Draw workspace boundary lines\n",
    "\t\tself._draw_workspace_lines()\n",
    "\t\tself.target_debug_items = [] # Store IDs of target visualization\n",
    "\n",
    "\t\t# Load Cube\n",
    "\t\tself.cube_id = p.loadURDF(\"cube_small.urdf\", basePosition=[0, 0, -10])\n",
    "\n",
    "\t\t# Initialize Robot\n",
    "\t\tself.robot = RobotController(\n",
    "\t\t\t\"franka_panda/panda.urdf\", \n",
    "\t\t\tscale=1.5,\n",
    "\t\t\tinitial_base_pos=[-0.3, 0, self.z_height - 0.4]\n",
    "\t\t)\n",
    "\n",
    "\t\t# Set specific speeds for RL steps\n",
    "\t\tself.robot.ee_velocity = 0.5\n",
    "\t\tself.robot.gripper_rot_velocity = 2.0\n",
    "\n",
    "\tdef _draw_workspace_lines(self):\n",
    "\t\t\"\"\"Draws debug lines to visualize the workspace boundaries.\"\"\"\n",
    "\t\tz = self.z_height\n",
    "\t\tcorners = [\n",
    "\t\t\t[self.x_min, self.y_min, z],\n",
    "\t\t\t[self.x_max, self.y_min, z],\n",
    "\t\t\t[self.x_max, self.y_max, z],\n",
    "\t\t\t[self.x_min, self.y_max, z]\n",
    "\t\t]\n",
    "\t\t\n",
    "\t\tline_color = [1, 0, 0] # Red\n",
    "\t\tline_width = 2\n",
    "\t\t\n",
    "\t\t# Draw lines connecting corners\n",
    "\t\tfor i in range(4):\n",
    "\t\t\tstart_pos = corners[i]\n",
    "\t\t\tend_pos = corners[(i + 1) % 4]\n",
    "\t\t\tp.addUserDebugLine(start_pos, end_pos, lineColorRGB=line_color, lineWidth=line_width)\n",
    "\n",
    "\tdef _get_direction_vector(self, action_idx):\n",
    "\t\t\"\"\"Calculates the velocity vector for a movement action index using sin/cos.\"\"\"\n",
    "\t\t# Calculate angle for this direction index: i * (2pi / n)\n",
    "\t\tangle = action_idx * (2 * np.pi / self.n_directions)\n",
    "\t\t\n",
    "\t\t# Calculate unit vector components\n",
    "\t\tdx = math.cos(angle)\n",
    "\t\tdy = math.sin(angle)\n",
    "\t\t\n",
    "\t\t# Scale by robot speed\n",
    "\t\tvx = dx * self.robot.ee_velocity\n",
    "\t\tvy = dy * self.robot.ee_velocity\n",
    "\t\t\n",
    "\t\treturn [vx, vy, 0] # Z velocity is 0 for planar movement\n",
    "\n",
    "\tdef _draw_target_circle(self, x, y):\n",
    "\t\t\"\"\"Draws a debug circle at the target position.\"\"\"\n",
    "\t\t# Remove old target visualization\n",
    "\t\tfor item in self.target_debug_items:\n",
    "\t\t\tp.removeUserDebugItem(item)\n",
    "\t\tself.target_debug_items = []\n",
    "\t\t\n",
    "\t\tradius = 0.03\n",
    "\t\tz = self.z_height + 0.005\n",
    "\t\tcolor = [0, 1, 0] # Green\n",
    "\t\tnum_segments = 12\n",
    "\t\t\n",
    "\t\tfor i in range(num_segments):\n",
    "\t\t\tangle = 2 * math.pi * i / num_segments\n",
    "\t\t\tnext_angle = 2 * math.pi * (i + 1) / num_segments\n",
    "\t\t\tp1 = [x + radius * math.cos(angle), y + radius * math.sin(angle), z]\n",
    "\t\t\tp2 = [x + radius * math.cos(next_angle), y + radius * math.sin(next_angle), z]\n",
    "\t\t\titem_id = p.addUserDebugLine(p1, p2, lineColorRGB=color, lineWidth=3)\n",
    "\t\t\tself.target_debug_items.append(item_id)\n",
    "\n",
    "\tdef _get_observation(self):\n",
    "\t\t\"\"\"Returns the state: [EE_x_rel, EE_y_rel, EE_yaw, Cube_x_rel, Cube_y_rel, Target_x_rel, Target_y_rel]\"\"\"\n",
    "\t\t# Get raw positions\n",
    "\t\tee_pos, ee_orn = self.robot.get_ee_pose()\n",
    "\t\tcube_pos, _ = p.getBasePositionAndOrientation(self.cube_id)\n",
    "\n",
    "\t\t# Calculate center of workspace\n",
    "\t\tcenter_x = (self.x_min + self.x_max) / 2\n",
    "\t\tcenter_y = (self.y_min + self.y_max) / 2\n",
    "\n",
    "\t\t# Relative EE Position (XY)\n",
    "\t\tee_x_rel = ee_pos[0] - center_x\n",
    "\t\tee_y_rel = ee_pos[1] - center_y\n",
    "\n",
    "\t\t# EE Yaw (Orientation)\n",
    "\t\tee_euler = p.getEulerFromQuaternion(ee_orn)\n",
    "\t\tee_yaw = ee_euler[2]\n",
    "\n",
    "\t\t# Relative Cube Position (XY)\n",
    "\t\tcube_x_rel = cube_pos[0] - center_x\n",
    "\t\tcube_y_rel = cube_pos[1] - center_y\n",
    "\t\t\n",
    "\t\t# Relative Target Position (XY)\n",
    "\t\ttarget_x_rel = self.target_pos[0] - center_x\n",
    "\t\ttarget_y_rel = self.target_pos[1] - center_y\n",
    "\n",
    "\t\treturn np.array([ee_x_rel, ee_y_rel, ee_yaw, cube_x_rel, cube_y_rel, target_x_rel, target_y_rel], dtype=np.float32)\n",
    "\n",
    "\tdef step(self, action):\n",
    "\t\tself.current_step += 1\n",
    "\t\tlin_vel = [0, 0, 0]\n",
    "\t\trot_vel = 0\n",
    "\t\t\n",
    "\t\t# --- Map Discrete Action to Continuous Velocity ---\n",
    "\t\tif 0 <= action < self.n_directions:\n",
    "\t\t\tlin_vel = self._get_direction_vector(action)\n",
    "\t\telif action == self.n_directions:\n",
    "\t\t\trot_vel = self.robot.gripper_rot_velocity\n",
    "\t\telif action == self.n_directions + 1:\n",
    "\t\t\trot_vel = -self.robot.gripper_rot_velocity\n",
    "\n",
    "\t\t# --- Apply Control ---\n",
    "\t\tself.robot.move_ee_velocity(lin_vel, maintain_height=self.z_height)\n",
    "\t\tself.robot.rotate_gripper_velocity(rot_vel)\n",
    "\t\t\n",
    "\t\t# --- Step Simulation ---\n",
    "\t\t# Execute action for multiple physics steps (Action Repetition)\n",
    "\t\t# 20 steps * 1/240s ~= 0.083s per RL step. \n",
    "\t\t# This makes the robot move ~4cm per step and reduces the step counter frequency.\n",
    "\t\tfor _ in range(20):\n",
    "\t\t\tp.stepSimulation()\n",
    "\t\t\tif self.render_mode == 'human':\n",
    "\t\t\t\ttime.sleep(self.sim.time_step)\n",
    "\n",
    "\t\t# --- Get Observation ---\n",
    "\t\tobservation = self._get_observation()\n",
    "\t\t\n",
    "\t\t# --- Check Boundaries & Calculate Reward ---\n",
    "\t\treward = 0.0\n",
    "\t\tterminated = False\n",
    "\t\ttruncated = False\n",
    "\t\t\n",
    "\t\t# Check Step Limit\n",
    "\t\tif self.current_step >= self.max_steps:\n",
    "\t\t\ttruncated = True\n",
    "\n",
    "\t\tee_pos, _ = self.robot.get_ee_pose()\n",
    "\t\tcube_pos, _ = p.getBasePositionAndOrientation(self.cube_id)\n",
    "\t\t\n",
    "\t\t# 1. Boundary Check (Punishment)\n",
    "\t\tx, y, z = ee_pos\n",
    "\t\tif x < self.x_min or x > self.x_max or y < self.y_min or y > self.y_max:\n",
    "\t\t\treward = -10.0\n",
    "\t\telse:\n",
    "\t\t\t# 2. Distance Rewards\n",
    "\t\t\tdist_cube_target = math.sqrt((cube_pos[0] - self.target_pos[0])**2 + (cube_pos[1] - self.target_pos[1])**2)\n",
    "\t\t\tdist_ee_cube = math.sqrt((ee_pos[0] - cube_pos[0])**2 + (ee_pos[1] - cube_pos[1])**2)\n",
    "\t\t\t\n",
    "\t\t\t# Action Cost (Encourage efficiency)\n",
    "\t\t\taction_cost = -0.05\n",
    "\n",
    "\t\t\t# Combined Reward\n",
    "\t\t\t# We prioritize moving the cube (2.0) over just reaching the cube (0.5)\n",
    "\t\t\treward = action_cost - (2.0 * dist_cube_target + 0.5 * dist_ee_cube)\n",
    "\t\t\t\n",
    "\t\t\t# Success Bonus\n",
    "\t\t\tif dist_cube_target < 0.05:\n",
    "\t\t\t\treward += 20.0\n",
    "\t\t\t\tterminated = True\n",
    "\t\t\t\tprint(\"Target Reached!\")\n",
    "\t\t\n",
    "\t\tinfo = {}\n",
    "\t\t\n",
    "\t\treturn observation, reward, terminated, truncated, info\n",
    "\n",
    "\tdef reset(self, seed=None, options=None):\n",
    "\t\tsuper().reset(seed=seed)\n",
    "\t\tself.current_step = 0\n",
    "\t\t\n",
    "\t\t# 1. Generate Random Spawn Position for Robot\n",
    "\t\t# Use self.np_random for Gymnasium compatibility\n",
    "\t\trobot_x = self.np_random.uniform(self.x_min, self.x_max)\n",
    "\t\trobot_y = self.np_random.uniform(self.y_min, self.y_max)\n",
    "\t\ttarget_pos = [robot_x, robot_y, self.z_height]\n",
    "\t\t\n",
    "\t\t# Fixed orientation (gripper pointing down)\n",
    "\t\ttarget_orn = [math.pi, 0, 0]\n",
    "\t\t\n",
    "\t\t# 2. Calculate Joint Angles and Reset Robot\n",
    "\t\tjoint_poses = self.robot.inverse_kinematics(target_pos, target_orn)\n",
    "\t\tfor i in range(7):\n",
    "\t\t\tp.resetJointState(self.robot.robot_id, i, joint_poses[i])\n",
    "\t\t\tself.robot.joints[i].set_position(joint_poses[i])\n",
    "\t\t\t\n",
    "\t\t# 3. Generate Random Spawn Position for Cube (avoiding robot)\n",
    "\t\tmin_dist = 0.15 \n",
    "\t\twhile True:\n",
    "\t\t\tcube_x = self.np_random.uniform(self.x_min, self.x_max)\n",
    "\t\t\tcube_y = self.np_random.uniform(self.y_min, self.y_max)\n",
    "\t\t\tdist = math.sqrt((cube_x - robot_x)**2 + (cube_y - robot_y)**2)\n",
    "\t\t\tif dist > min_dist:\n",
    "\t\t\t\tbreak\n",
    "\t\tp.resetBasePositionAndOrientation(self.cube_id, [cube_x, cube_y, self.z_height], [0, 0, 0, 1])\n",
    "\t\t\n",
    "\t\t# 4. Generate Random Target Position (avoiding cube start)\n",
    "\t\twhile True:\n",
    "\t\t\ttarget_x = self.np_random.uniform(self.x_min, self.x_max)\n",
    "\t\t\ttarget_y = self.np_random.uniform(self.y_min, self.y_max)\n",
    "\t\t\tdist = math.sqrt((target_x - cube_x)**2 + (target_y - cube_y)**2)\n",
    "\t\t\tif dist > 0.1: # Ensure target isn't exactly where cube spawns\n",
    "\t\t\t\tbreak\n",
    "\t\t\n",
    "\t\tself.target_pos = [target_x, target_y]\n",
    "\t\tself._draw_target_circle(target_x, target_y)\n",
    "\t\t\n",
    "\t\t# Get initial observation\n",
    "\t\tobservation = self._get_observation()\n",
    "\t\t\n",
    "\t\treturn observation, {}\n",
    "\n",
    "\tdef run_interactive(self):\n",
    "\t\t\"\"\"Allows manual control of the robot using keyboard arrow keys.\"\"\"\n",
    "\t\tprint(\"Interactive Mode: Use Arrow Keys to Move, Q/E to Rotate.\")\n",
    "\t\tprint(\"Press 'R' to Reset.\")\n",
    "\t\t\n",
    "\t\tself.reset()\n",
    "\t\t\n",
    "\t\t# Calculate indices for cardinal directions based on n_directions\n",
    "\t\t# 0 is usually East (Right), increasing counter-clockwise\n",
    "\t\tidx_right = 0\n",
    "\t\tidx_up = int(self.n_directions / 4)\n",
    "\t\tidx_left = int(self.n_directions / 2)\n",
    "\t\tidx_down = int(3 * self.n_directions / 4)\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\twhile True:\n",
    "\t\t\t\tkeys = p.getKeyboardEvents()\n",
    "\t\t\t\taction = -1 \n",
    "\t\t\t\t\n",
    "\t\t\t\t# Map keys to actions dynamically\n",
    "\t\t\t\tif p.B3G_RIGHT_ARROW in keys and keys[p.B3G_RIGHT_ARROW] & p.KEY_IS_DOWN:\n",
    "\t\t\t\t\taction = idx_right\n",
    "\t\t\t\telif p.B3G_UP_ARROW in keys and keys[p.B3G_UP_ARROW] & p.KEY_IS_DOWN:\n",
    "\t\t\t\t\taction = idx_up\n",
    "\t\t\t\telif p.B3G_LEFT_ARROW in keys and keys[p.B3G_LEFT_ARROW] & p.KEY_IS_DOWN:\n",
    "\t\t\t\t\taction = idx_left\n",
    "\t\t\t\telif p.B3G_DOWN_ARROW in keys and keys[p.B3G_DOWN_ARROW] & p.KEY_IS_DOWN:\n",
    "\t\t\t\t\taction = idx_down\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Rotation\n",
    "\t\t\t\tif ord('q') in keys and keys[ord('q')] & p.KEY_IS_DOWN:\n",
    "\t\t\t\t\taction = self.n_directions # Rotate Positive\n",
    "\t\t\t\telif ord('e') in keys and keys[ord('e')] & p.KEY_IS_DOWN:\n",
    "\t\t\t\t\taction = self.n_directions + 1 # Rotate Negative\n",
    "\n",
    "\t\t\t\t# Reset\n",
    "\t\t\t\tif ord('r') in keys and keys[ord('r')] & p.KEY_IS_DOWN:\n",
    "\t\t\t\t\tprint(\"Resetting...\")\n",
    "\t\t\t\t\tself.reset()\n",
    "\t\t\t\t\ttime.sleep(0.5)\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tif action != -1:\n",
    "\t\t\t\t\t# Step environment (counts as an action step)\n",
    "\t\t\t\t\tobs, reward, terminated, truncated, info = self.step(action)\n",
    "\t\t\t\t\tif terminated or truncated:\n",
    "\t\t\t\t\t\tprint(f\"Episode ended. Reward: {reward:.2f}\")\n",
    "\t\t\t\t\t\tself.reset()\n",
    "\t\t\t\t\t\ttime.sleep(0.5)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t# Idle mode: Maintain position, don't count steps\n",
    "\t\t\t\t\t# We must explicitly stop the robot, otherwise previous velocity persists\n",
    "\t\t\t\t\tself.robot.move_ee_velocity([0, 0, 0], maintain_height=self.z_height)\n",
    "\t\t\t\t\tself.robot.rotate_gripper_velocity(0)\n",
    "\t\t\t\t\tp.stepSimulation()\n",
    "\t\t\t\t\ttime.sleep(self.sim.time_step)\n",
    "\t\t\t\t\t\n",
    "\t\texcept KeyboardInterrupt:\n",
    "\t\t\tprint(\"Exiting Interactive Mode...\")\n",
    "\n",
    "\tdef close(self):\n",
    "\t\tself.sim.close()\n",
    "\n",
    "# --- Main Execution using Gym Env ---\n",
    "env = RobotGymEnv(n_directions=8, render_mode='human', max_steps=50)\n",
    "cam = CameraManager(target_pos=[0, 0, 0], distance=2, yaw=20, pitch=-45)\n",
    "# env.run_interactive()\n",
    "observation, info = env.reset()\n",
    "\n",
    "print(\"Starting Gym Environment Loop...\")\n",
    "try:\n",
    "\tenv.reset()\n",
    "\twhile True:\n",
    "\t\t# Sample a random action\n",
    "\t\taction = env.action_space.sample()\n",
    "\t\t\n",
    "\t\t# Step the environment\n",
    "\t\tobservation, reward, terminated, truncated, info = env.step(action)\n",
    "\t\t\n",
    "\t\tif terminated or truncated:\n",
    "\t\t\tprint(\"Resetting environment...\")\n",
    "\t\t\tobservation, info = env.reset()\n",
    "\t\t\ttime.sleep(0.5) # Pause briefly on reset\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "\tprint(\"Stopping...\")\n",
    "finally:\n",
    "\tenv.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
